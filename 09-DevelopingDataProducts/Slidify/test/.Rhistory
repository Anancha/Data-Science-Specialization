install.packages("shiny")
library(shiny)
?runApp
runApp()
getwd()
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example1")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example1")
## Example run:  runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example1")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example2")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example3")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example3")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example3")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example4_prediction_function")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example4_creating_prediction_function")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example5_plot")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example5_plot")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example5_plot")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example5_plot")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example5_plot")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example6")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example6")
x <- 0
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example6")
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example6", display.mode = 'showcase')
runApp("C:/Users/bliap/Documents/GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Shiny/Example7_button")
library(manipulate) manipulate(plot(1:x), x = slider(1, 100))
library(manipulate); manipulate(plot(1:x), x = slider(1, 100))
require(rCharts)
install.packages("rCharts")
require(devtools)
install.packages("devtools")
install_github('rCharts', 'ramnathv')
require(devtools)
install_github('rCharts', 'ramnathv')
require(rCharts)
##---------------------------rCharts-------------------------------
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nplot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
n1$save('fig/n1.html', cdn = TRUE)
cat('<iframe src = "fig/n1.html" width = 100%, height = 600> </iframe>')
?nplot
require(rCharts)
?nplot
?rplot
?nPlot
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group = 'Eye', type = 'multiBarChart', data = subset(haireye, Sex == 'Male'))
n1$save('fig/n1.html', cdn = TRUE)
cat('<iframe src = "fig/n1.html" width = 100%, height = 600> </iframe>')
library(caret)
library(lattice)
library(ggplot2)
library(caret)
x <- [1, 2, 3, 4, 5]
x <- []
x = [1, 2, 3, 4, 5]
x <- (1, 2, 3, 4, 5)
x <- c(1, 2, 3, 4, 5, 6, 7, 8)
x
spam(x)
?spam
??spam
library(lattice)
library(ggplot2)
library(caret)
library(kernlab)
data(sapm)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)  ## p is the percent of training set
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit
?train
modelFit <- train(type ~ ., data = training, method = "glm")
install.packages("e1071")
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit
modelFit$finalModel
prediction <- predict(modelFit, newdata = testing)
predictions
predictions <- predict(modelFit, newdata = testing)
predictions
fusion matrix
confusionMatrix(predictions, testing$type)
library(lattice)
library(ggplot2)
library(caret)
library(kernlab)
data(sapm)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)  ## p is the percent of training set
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
head(spam$type)
# k-fold
set.seed(32323)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE)  ## k is the number of folds, list = TRUE means return list
sapply(folds, length)
folds
class(folds)
folds[1]
folds$Fold01
folds[[1]][1:10]
folds[[2]][1:10]
folds[[4]][1:10]
set.seed(32323)
folds <- createResample(y = spam$type, times = 10, list = TRUE)
sapply(folds, length)
set.seed(32323)
time <- 1:1000
folds <- createTimeSlices(y = time, initialWindow = 20, horizon = 10)
names(folds)
head(folds)
folds$train[[1]]
folds$test[[1]]
##------------------------------training options-------------------------------------
library(lattice)
library(ggplot2)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)  ## p is the percent of training set
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
modelFit <- train(type ~ .,data = training, method = "glm")
warnings()
args(train.default)
args(train.Control)
args(trainControl)
##----------------------------plotting predictors-----------------------------
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
data(Wage)
?ISLR
library(ISLR)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
head(Wage$wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
dim(training)
dim(testing)
class(testing)
head(testing)
ng set
featurePlot(x = training[, c("age", "education", "jobclass")], y = training$wage, plot = "pairs")
## ggplot2 package
qplot(age, wage, data = training)
qplot(age, wage, colour = jobclass, data = training)
qq <- qplot(age, wage, colour = education, data = training)
qq + geom_smooth(method = 'lm', formula = y ~ x)
library(Hmisc)
cutWage <- cut2(training$wage, g = 3)
table(cutWage)
## boxplots with cut2
p1 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot"))
p1
## boxplot with points overlayed
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol = 2)
??grid.arrange
library(girdExtra)
install.packages("gridExtra")
library(girdExtra)
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol = 2)
## boxplot with points overlayed
library(gridExtra)
p2 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot", "jitter"))
grid.arrange(p1, p2, ncol = 2)
t1 <- table(cutWage, training$jobclass)
t1
cutWage
prop.table(t1, 1)
qplot(wage, colour = education, data = training, geom = "density")
##-------------------------------preprocessing-------------------------
library(lattice)
library(ggplot2)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)  ## p is the percent of training set
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
hist(training$capitalAve, main = "", xlab = "ave. capital run length")
head(training)
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAve <- (trainCapAve - mean(trainCapAve)) / sd(trainCapAve)
mean(trainCapAve)
sd(trainCapAve)
trainCapAve <- training$capitalAve
trainCapAve <- (trainCapAve - mean(trainCapAve)) / sd(trainCapAve)
mean(trainCapAve)
sd(trainCapAve)
testCapAve <- testing$capitalAve
testCapAves <- (testCapAve - mean(trainCapAve)) / sd(trainCapAve)     ## use mean and sd of trainCapAve
mean(testCapAveS)
sd(testCapAveS)
## standardizing test set
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve)) / sd(trainCapAve)     ## use mean and sd of trainCapAve
mean(testCapAveS)
sd(testCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve)) / sd(trainCapAve)     ## use mean and sd of trainCapAve
mean(testCapAveS)
sd(testCapAveS)
trainCapAve <- training$capitalAve
trainCapAve <- (trainCapAve - mean(trainCapAve)) / sd(trainCapAve)
## standardizing test set
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve)) / sd(trainCapAve)     ## use mean and sd of trainCapAve
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[, -58], method = c("center", "scale"))
trainCapAveS <- predict(preObj, training[, -58])$capitalAve
mean(trainCapAveS)
testCapAveS <- predict(preObj, testing[, -58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~ ., data = training, preProcess = c("center", "scale"), method = "glm")
modelFit
summary(training)
str(training)
preObj <- preProcess(training[, -58], method = c("BoxCox"))
trainCapAveS <- predict(preObj, training[, -58])$capitalAve
par(mfrow = c(1, 2))
hist(trainCapAveS)
qqnorm(trainCapAveS)
## standardizing imputing data, deal with missing data
set.seed(13343)
## make some NA values
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size = 1, prob = 0.05) == 1
training$capAve[selectNA] <- NA
## impute and standardize
preObj <- preProcess(training[, -58], method = "knnImpute")
capAve <- predict(preObj, training[, -58])$capAve
## standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth - mean(capAveTruth)) / sd(capAveTruth)
install.packages(RANN)
install.packages("RANN")
library(RANN)
set.seed(13343)
## make some NA values
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1], size = 1, prob = 0.05) == 1
training$capAve[selectNA] <- NA
## impute and standardize
preObj <- preProcess(training[, -58], method = "knnImpute")
capAve <- predict(preObj, training[, -58])$capAve
## standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth - mean(capAveTruth)) / sd(capAveTruth)
##--------------------------covariate creation-------------------------
library(ISLR)
library(caret)
data(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
## common covariates to add, dummy variables
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data = training)
head(predict(dummies, newdata = training))
class(dummies)
dummies
## removing zero covariates
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
## spline basis
library(splines)
bsBasis <- bs(training$age, df = 3)
bsBasis
## fitting curves with splines
lm1 <- lm(wage ~ bsBasis, data = training)
plot(training$age, training$wage, pch = 19, cex = 0.5)
points(training$age, predict(lm1, newdata = training), col = "red", pch = 19, cex = 0.5)
predict(bsBasis, age = testing$age)
## correlated predictors
library(kernlab)
library(caret)
data(Wage)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M > 0.8, arr.ind = TRUE)
library(kernlab)
library(caret)
data(Wage)
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M > 0.8, arr.ind = TRUE)
M <- abs(cor(training[, -58]))
diag(M) <- 0
which(M > 0.8, arr.ind = T)
names(spam[c(34, 32)])
plot(spam[, 34], spam[, 32])
smallSpam <- spam[, c(34, 32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[, 1], prComp$x[, 2])
prComp$rotation
## PCA on SPAM data
typeColor <- ((spam$type == "spam") * 1 + 1)
prCompe <- prcomp(log10(spam[, -58] + 1))
plot(prComp$x[, 1], prComp$x[, 2], col = typeColor, xlab = "PC1", ylab = "PC2")
## PCA with caret
preProc <- preProcess(log10(spam[, -58] + 1), method = "pca", pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[, 1], spamPC[, 2], col = typeColor)
head(spam[, c(34, 32)])
head(spam)
smallSpam <- spam[, c(34, 32)]
prComp <- prcomp(smallSpam)
prComp
prComp$x
prComp
?prcomp
dim(prcomp)
names(prcomp)
head(prComp)
head(prComp)
dim(prComp)
typeColor <- ((spam$type == "spam") * 1 + 1)
prCompe <- prcomp(log10(spam[, -58] + 1))
plot(prComp$x[, 1], prComp$x[, 2], col = typeColor, xlab = "PC1", ylab = "PC2")
## PCA with caret
preProc <- preProcess(log10(spam[, -58] + 1), method = "pca", pcaComp = 2)
spamPC <- predict(preProc, log10(spam[, -58] + 1))
plot(spamPC[, 1], spamPC[, 2], col = typeColor)
## preprocessing with PCA
preProc <- preProcess(log10(training[, -58] + 1))
trainPC <- predict(preProc, log10(training[, -58] + 1))
modelFit <- train(training$type ~ ., method = "glm", data = trainPC)
testPC <- predict(preProc, log10(testing[, -58] + 1))
confusionMatrix(testing$type, predict(modelFit, testing))
modelFit <- train(training$type ~ ., method = "glm", preProcess = "pca", data = training)
confusionMatrix(testing$type, predict(modelFit, testing))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete)
cutCs <- cut2(concrete$CompressiveStrength, g = 4)
cutCs
cutCs <- cut2(concrete$CompressiveStrength, g = 3)
cutCs <- cut2(concrete$CompressiveStrength, g = 3)
table(cutCs)
qplot(training$CompressiveStrength)
qplot(training$CompressiveStrength, geom = "density")
head(concrete, 10)
str(concrete)
summary(concrete)
cutFlyAsh <- cut2(training$FlyAsh, g = 3)
table(cutFlyAsh)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
library(Hmisc)
cutWage <- cut2(training$wage, g = 3)
table(cutWage)
p1 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot"))
p1
p1 <- qplot(cutFlyAsh, CompressiveStrength, data = training, fill = cutFlyAsh, geom = c("boxplot"))
p1 <- qplot(cutFlyAsh, CompressiveStrength, data = training, fill = cutFlyAsh, geom = c("boxplot"))
p1
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
p1 <- qplot(cutFlyAsh, CompressiveStrength, data = training, fill = cutFlyAsh, geom = c("boxplot"))
p1
?predict
?train
args(train.default)
##------------------------------------caret---------------------------------
## SPAM Example
library(lattice)
library(ggplot2)
library(caret)
library(kernlab)
data(spam)
## data spliting
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)  ## p is the percent of training set
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(training)
set.seed(32343)
modelFit <- train(type ~ ., data = training, method = "glm")
cutWage <- cut2(training$wage, g = 3)
##----------------------------plotting predictors-----------------------------
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y = Wage$wage, p = 0.7, list = FALSE)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
dim(training)
dim(testing)
library(Hmisc)
cutWage <- cut2(training$wage, g = 3)
class(cutWage)
head(cutWage)
summary(cutWage)
table(cutWage)
head(cutWage, 10)
dim(cutWage)
cutWage
head(training$wage)
tail(training$wage)
p1 <- qplot(cutWage, age, data = training, fill = cutWage, geom = c("boxplot"))
p1
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement, g = 3))
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement, g = 4))
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement, g = 10))
suppressPackageStartupMessages(library(googleVis))
M <- gvisMontionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, "chart")
install.packages("googlevis")
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
M <- gvisMontionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, "chart")
suppressPackageStartupMessages(library(googleVis))
M <- gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, "chart")
G <- gvisGeochart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width = 600, height = 400, region = "150"))
print(G, "chart")
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width = 600, height = 400, region = "150"))
print(G, "chart")
library(devtools)
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install.packages("devtools")
getwd()
setwd("./GitHub/Data-Science-Specialization/09-DevelopiongDataProducts/Slidify")
library(slidify)
getwd()
setwd("./GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Slidify")
setwd("./GitHub/Data-Science-Specialization/09-DevelopingDataProducts/Slidify")
author('test')
slidify('index.Rmd')
library(knitr)
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
slidify('index.Rmd')
browseURL('index.html')
r date()
